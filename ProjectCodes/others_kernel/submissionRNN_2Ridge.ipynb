{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "37070448-9c94-480d-8ad4-55d84b7349b0",
    "_uuid": "c20c67f2226b24051e2d64a63555059d96969829"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#changes:\n",
    "#optimizing RNN and Ridge again\n",
    "#based on https://www.kaggle.com/valkling/mercari-rnn-2ridge-models-with-notes-0-42755\n",
    "#required libraries\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime \n",
    "start_real = datetime.now()\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input, Dropout, Dense, concatenate, GRU, Embedding, Flatten, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from nltk.corpus import stopwords\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "dd34009a-f007-487c-9acf-f653dbf05083",
    "_uuid": "41233bd862bb32f02ecb44fcd50dd6aeb97cf457",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set seed\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "da19503f-4c26-4289-a393-10979eec831b",
    "_uuid": "2283bddbecd96beda65dd05063efdb8ae7af3bd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (1482535, 8) ,test: (693359, 7)\n"
     ]
    }
   ],
   "source": [
    "#Load the train and test data\n",
    "train_df = pd.read_table('../input/train.tsv')\n",
    "test_df = pd.read_table('../input/test.tsv')\n",
    "#check the shape of the dataframes\n",
    "print('train:',train_df.shape, ',test:',test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN   35.0   \n",
       "4                            Women/Jewelry/Necklaces        NaN   44.0   \n",
       "\n",
       "   shipping                                   item_description  \n",
       "0         1                                 No description yet  \n",
       "1         0  This keyboard is in great condition and works ...  \n",
       "2         1  Adorable top with a hint of lace and a key hol...  \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...  \n",
       "4         0          Complete with certificate of authenticity  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the head\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "5c8ee26f-8e0f-4a41-9cda-9e3ab5345c8b",
    "_uuid": "a684c1c62a0be7051428097c89a3e9c70b66b3f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1481661, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing prices less than 3\n",
    "train_df = train_df.drop(train_df[(train_df.price < 3.0)].index)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "      <th>desc_len</th>\n",
       "      <th>name_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MLB Cincinnati Reds T Shirt Size XL</td>\n",
       "      <td>3</td>\n",
       "      <td>Men/Tops/T-shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>No description yet</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Razer BlackWidow Chroma Keyboard</td>\n",
       "      <td>3</td>\n",
       "      <td>Electronics/Computers &amp; Tablets/Components &amp; P...</td>\n",
       "      <td>Razer</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>This keyboard is in great condition and works ...</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AVA-VIV Blouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Tops &amp; Blouses/Blouse</td>\n",
       "      <td>Target</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Adorable top with a hint of lace and a key hol...</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Leather Horse Statues</td>\n",
       "      <td>1</td>\n",
       "      <td>Home/Home Décor/Home Décor Accents</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>New with tags. Leather horses. Retail for [rm]...</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24K GOLD plated rose</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Jewelry/Necklaces</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Complete with certificate of authenticity</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                                 name  item_condition_id  \\\n",
       "0         0  MLB Cincinnati Reds T Shirt Size XL                  3   \n",
       "1         1     Razer BlackWidow Chroma Keyboard                  3   \n",
       "2         2                       AVA-VIV Blouse                  1   \n",
       "3         3                Leather Horse Statues                  1   \n",
       "4         4                 24K GOLD plated rose                  1   \n",
       "\n",
       "                                       category_name brand_name  price  \\\n",
       "0                                  Men/Tops/T-shirts        NaN   10.0   \n",
       "1  Electronics/Computers & Tablets/Components & P...      Razer   52.0   \n",
       "2                        Women/Tops & Blouses/Blouse     Target   10.0   \n",
       "3                 Home/Home Décor/Home Décor Accents        NaN   35.0   \n",
       "4                            Women/Jewelry/Necklaces        NaN   44.0   \n",
       "\n",
       "   shipping                                   item_description  desc_len  \\\n",
       "0         1                                 No description yet         0   \n",
       "1         0  This keyboard is in great condition and works ...        36   \n",
       "2         1  Adorable top with a hint of lace and a key hol...        29   \n",
       "3         1  New with tags. Leather horses. Retail for [rm]...        32   \n",
       "4         0          Complete with certificate of authenticity         5   \n",
       "\n",
       "   name_len  \n",
       "0         7  \n",
       "1         4  \n",
       "2         2  \n",
       "3         3  \n",
       "4         4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# handling categorical variables\n",
    "def wordCount(text):\n",
    "    try:\n",
    "        if text == 'No description yet':\n",
    "            return 0\n",
    "        else:\n",
    "            text = text.lower()\n",
    "            words = [w for w in text.split(\" \")]\n",
    "            return len(words)\n",
    "    except: \n",
    "        return 0\n",
    "train_df['desc_len'] = train_df['item_description'].apply(lambda x: wordCount(x))\n",
    "test_df['desc_len'] = test_df['item_description'].apply(lambda x: wordCount(x))\n",
    "train_df['name_len'] = train_df['name'].apply(lambda x: wordCount(x))\n",
    "test_df['name_len'] = test_df['name'].apply(lambda x: wordCount(x))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#splitting category_name into subcategories\n",
    "def split_cat(text):\n",
    "    try: return text.split(\"/\")\n",
    "    except: return (\"No Label\", \"No Label\", \"No Label\")\n",
    "train_df['subcat_0'], train_df['subcat_1'], train_df['subcat_2'] = \\\n",
    "zip(*train_df['category_name'].apply(lambda x: split_cat(x)))\n",
    "test_df['subcat_0'], test_df['subcat_1'], test_df['subcat_2'] = \\\n",
    "zip(*test_df['category_name'].apply(lambda x: split_cat(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137342\n"
     ]
    }
   ],
   "source": [
    "#combine the train and test dataframes\n",
    "full_set = pd.concat([train_df,test_df])\n",
    "#handling brand_name\n",
    "all_brands = set(full_set['brand_name'].values)\n",
    "#fill NA values\n",
    "train_df.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "test_df.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "premissing = len(train_df.loc[train_df['brand_name'] == 'missing'])\n",
    "def brandfinder(line):\n",
    "    brand = line[0]\n",
    "    name = line[1]\n",
    "    namesplit = name.split(' ')\n",
    "    if brand == 'missing':\n",
    "        for x in namesplit:\n",
    "            if x in all_brands:\n",
    "                return name\n",
    "    if name in all_brands:\n",
    "        return name\n",
    "    return brand\n",
    "train_df['brand_name'] = train_df[['brand_name','name']].apply(brandfinder, axis = 1)\n",
    "test_df['brand_name'] = test_df[['brand_name','name']].apply(brandfinder, axis = 1)\n",
    "found = premissing-len(train_df.loc[train_df['brand_name'] == 'missing'])\n",
    "print(found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: 1466844 examples\n",
      "Validating on: 14817 examples\n",
      "Testing on: 693359 examples\n"
     ]
    }
   ],
   "source": [
    "# Scale target variable-price to log\n",
    "train_df[\"target\"] = np.log1p(train_df.price)\n",
    "# Split training examples into train/dev\n",
    "train_df, dev_df = train_test_split(train_df, random_state=123, train_size=0.99)\n",
    "# Calculate number of train/dev/test examples.\n",
    "n_trains = train_df.shape[0]\n",
    "n_devs = dev_df.shape[0]\n",
    "n_tests = test_df.shape[0]\n",
    "print(\"Training on:\", n_trains, \"examples\")\n",
    "print(\"Validating on:\", n_devs, \"examples\")\n",
    "print(\"Testing on:\", n_tests, \"examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate train - dev - test data for easy to handle\n",
    "full_df = pd.concat([train_df, dev_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling missing data...\n",
      "1    Electronics/Computers & Tablets/Components & P...\n",
      "1              Other/Office supplies/Shipping Supplies\n",
      "Name: category_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Filling missing values in combine dataset\n",
    "def fill_missing_values(df):\n",
    "    df.category_name.fillna(value=\"missing\", inplace=True)\n",
    "    df.brand_name.fillna(value=\"missing\", inplace=True)\n",
    "    df.item_description.fillna(value=\"missing\", inplace=True)\n",
    "    df.item_description.replace('No description yet',\"missing\", inplace=True)\n",
    "    return df\n",
    "\n",
    "print(\"Filling missing data...\")\n",
    "full_df = fill_missing_values(full_df)\n",
    "print(full_df.category_name[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing categorical data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing categorical data...\")\n",
    "le = LabelEncoder()\n",
    "le.fit(full_df.category_name)\n",
    "full_df['category'] = le.transform(full_df.category_name)\n",
    "\n",
    "le.fit(full_df.brand_name)\n",
    "full_df.brand_name = le.transform(full_df.brand_name)\n",
    "\n",
    "le.fit(full_df.subcat_0)\n",
    "full_df.subcat_0 = le.transform(full_df.subcat_0)\n",
    "\n",
    "le.fit(full_df.subcat_1)\n",
    "full_df.subcat_1 = le.transform(full_df.subcat_1)\n",
    "\n",
    "le.fit(full_df.subcat_2)\n",
    "full_df.subcat_2 = le.transform(full_df.subcat_2)\n",
    "\n",
    "del le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming text data to sequences...\n",
      "Fitting tokenizer...\n",
      "Transforming text to sequences...\n",
      "CPU times: user 3min 56s, sys: 1.96 s, total: 3min 57s\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Transforming text data to sequences...\")\n",
    "raw_text = np.hstack([full_df.item_description.str.lower(), full_df.name.str.lower(), full_df.category_name.str.lower()])\n",
    "\n",
    "print(\"Fitting tokenizer...\")\n",
    "tok_raw = Tokenizer()\n",
    "tok_raw.fit_on_texts(raw_text)\n",
    "\n",
    "print(\"Transforming text to sequences...\")\n",
    "full_df['seq_item_description'] = tok_raw.texts_to_sequences(full_df.item_description.str.lower())\n",
    "full_df['seq_name'] = tok_raw.texts_to_sequences(full_df.name.str.lower())\n",
    "\n",
    "del tok_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#constants to use in RNN model\n",
    "MAX_NAME_SEQ = 10\n",
    "MAX_ITEM_DESC_SEQ = 75\n",
    "MAX_CATEGORY_SEQ = 8\n",
    "MAX_TEXT = np.max([\n",
    "    np.max(full_df.seq_name.max()),\n",
    "    np.max(full_df.seq_item_description.max()),\n",
    "]) + 100\n",
    "MAX_CATEGORY = np.max(full_df.category.max()) + 1\n",
    "MAX_BRAND = np.max(full_df.brand_name.max()) + 1\n",
    "MAX_CONDITION = np.max(full_df.item_condition_id.max()) + 1\n",
    "MAX_DESC_LEN = np.max(full_df.desc_len.max()) + 1\n",
    "MAX_NAME_LEN = np.max(full_df.name_len.max()) + 1\n",
    "MAX_SUBCAT_0 = np.max(full_df.subcat_0.max()) + 1\n",
    "MAX_SUBCAT_1 = np.max(full_df.subcat_1.max()) + 1\n",
    "MAX_SUBCAT_2 = np.max(full_df.subcat_2.max()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.6 s, sys: 1.56 s, total: 33.1 s\n",
      "Wall time: 33.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#transform the data for RNN model\n",
    "def get_rnn_data(dataset):\n",
    "    X = {\n",
    "        'name': pad_sequences(dataset.seq_name, maxlen=MAX_NAME_SEQ),\n",
    "        'item_desc': pad_sequences(dataset.seq_item_description, maxlen=MAX_ITEM_DESC_SEQ),\n",
    "        'brand_name': np.array(dataset.brand_name),\n",
    "        'category': np.array(dataset.category),\n",
    "        'item_condition': np.array(dataset.item_condition_id),\n",
    "        'num_vars': np.array(dataset[[\"shipping\"]]),\n",
    "        'desc_len': np.array(dataset[[\"desc_len\"]]),\n",
    "        'name_len': np.array(dataset[[\"name_len\"]]),\n",
    "        'subcat_0': np.array(dataset.subcat_0),\n",
    "        'subcat_1': np.array(dataset.subcat_1),\n",
    "        'subcat_2': np.array(dataset.subcat_2),\n",
    "    }\n",
    "    return X\n",
    "\n",
    "train = full_df[:n_trains]\n",
    "dev = full_df[n_trains:n_trains+n_devs]\n",
    "test = full_df[n_trains+n_devs:]\n",
    "\n",
    "X_train = get_rnn_data(train)\n",
    "Y_train = train.target.values.reshape(-1, 1)\n",
    "\n",
    "X_dev = get_rnn_data(dev)\n",
    "Y_dev = dev.target.values.reshape(-1, 1)\n",
    "\n",
    "X_test = get_rnn_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#our own loss function\n",
    "def root_mean_squared_logarithmic_error(y_true, y_pred):\n",
    "    first_log = K.log(K.clip(y_pred, K.epsilon(), None) + 1.)\n",
    "    second_log = K.log(K.clip(y_true, K.epsilon(), None) + 1.)\n",
    "    return K.sqrt(K.mean(K.square(first_log - second_log), axis=-1)+0.0000001)\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)+0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "brand_name (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_condition (InputLayer)     (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "desc_len (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "name_len (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subcat_0 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subcat_1 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subcat_2 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_desc (InputLayer)          (None, 75)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "name (InputLayer)               (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 10)        1791400     brand_name[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 1, 5)         30          item_condition[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 1, 5)         1230        desc_len[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 1, 5)         90          name_len[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_7 (Embedding)         (None, 1, 10)        110         subcat_0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 1, 10)        1140        subcat_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 1, 10)        8830        subcat_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 75, 60)       19321200    item_desc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 10, 20)       6440400     name[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 10)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 5)            0           embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 5)            0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 5)            0           embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 10)           0           embedding_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 10)           0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 10)           0           embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 16)           3696        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (None, 8)            696         embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "num_vars (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 80)           0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 gru_1[0][0]                      \n",
      "                                                                 gru_2[0][0]                      \n",
      "                                                                 num_vars[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 512)          41472       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          32896       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            65          dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,782,839\n",
      "Trainable params: 27,782,839\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "CPU times: user 644 ms, sys: 0 ns, total: 644 ms\n",
      "Wall time: 638 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#build the model\n",
    "np.random.seed(123)\n",
    "\n",
    "def new_rnn_model(lr=0.001, decay=0.0):\n",
    "    name = Input(shape=[X_train[\"name\"].shape[1]], name=\"name\")\n",
    "    item_desc = Input(shape=[X_train[\"item_desc\"].shape[1]], name=\"item_desc\")\n",
    "    brand_name = Input(shape=[1], name=\"brand_name\")\n",
    "    item_condition = Input(shape=[1], name=\"item_condition\")\n",
    "    num_vars = Input(shape=[X_train[\"num_vars\"].shape[1]], name=\"num_vars\")\n",
    "    desc_len = Input(shape=[1], name=\"desc_len\")\n",
    "    name_len = Input(shape=[1], name=\"name_len\")\n",
    "    subcat_0 = Input(shape=[1], name=\"subcat_0\")\n",
    "    subcat_1 = Input(shape=[1], name=\"subcat_1\")\n",
    "    subcat_2 = Input(shape=[1], name=\"subcat_2\")\n",
    "\n",
    "    # Embeddings layers (adjust outputs to help model)\n",
    "    emb_name = Embedding(MAX_TEXT, 20)(name)\n",
    "    emb_item_desc = Embedding(MAX_TEXT, 60)(item_desc)\n",
    "    emb_brand_name = Embedding(MAX_BRAND, 10)(brand_name)\n",
    "    emb_item_condition = Embedding(MAX_CONDITION, 5)(item_condition)\n",
    "    emb_desc_len = Embedding(MAX_DESC_LEN, 5)(desc_len)\n",
    "    emb_name_len = Embedding(MAX_NAME_LEN, 5)(name_len)\n",
    "    emb_subcat_0 = Embedding(MAX_SUBCAT_0, 10)(subcat_0)\n",
    "    emb_subcat_1 = Embedding(MAX_SUBCAT_1, 10)(subcat_1)\n",
    "    emb_subcat_2 = Embedding(MAX_SUBCAT_2, 10)(subcat_2)\n",
    "    \n",
    "\n",
    "    # rnn layers (GRUs are faster than LSTMs and speed is important here)\n",
    "    rnn_layer1 = GRU(16) (emb_item_desc)\n",
    "    rnn_layer2 = GRU(8) (emb_name)\n",
    "\n",
    "    # main layers\n",
    "    main_l = concatenate([\n",
    "        Flatten() (emb_brand_name)\n",
    "        , Flatten() (emb_item_condition)\n",
    "        , Flatten() (emb_desc_len)\n",
    "        , Flatten() (emb_name_len)\n",
    "        , Flatten() (emb_subcat_0)\n",
    "        , Flatten() (emb_subcat_1)\n",
    "        , Flatten() (emb_subcat_2)\n",
    "        , rnn_layer1\n",
    "        , rnn_layer2\n",
    "        , num_vars\n",
    "    ])\n",
    "    \n",
    "    # (incressing the nodes or adding layers does not effect the time quite as much as the rnn layers)\n",
    "    main_l = Dropout(0.1)(Dense(512,kernel_initializer='normal',activation='relu') (main_l))\n",
    "    main_l = Dropout(0.1)(Dense(256,kernel_initializer='normal',activation='relu') (main_l))\n",
    "    main_l = Dropout(0.1)(Dense(128,kernel_initializer='normal',activation='relu') (main_l))\n",
    "    main_l = Dropout(0.1)(Dense(64,kernel_initializer='normal',activation='relu') (main_l))\n",
    "\n",
    "    # the output layer.\n",
    "    output = Dense(1, activation=\"linear\") (main_l)\n",
    "    \n",
    "    model = Model([name, item_desc, brand_name , item_condition, \n",
    "                   num_vars, desc_len, name_len, subcat_0, subcat_1, subcat_2], output)\n",
    "\n",
    "    optimizer = Adam(lr=lr, decay=decay)\n",
    "    \n",
    "    # (mean squared error loss function works as well as custom functions)  \n",
    "    model.compile(loss = 'mse', optimizer = optimizer)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = new_rnn_model()\n",
    "model.summary()\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1466844 samples, validate on 14817 samples\n",
      "Epoch 1/2\n",
      "1466844/1466844 [==============================] - 969s 660us/step - loss: 0.3458 - val_loss: 0.1931\n",
      "Epoch 2/2\n",
      "1466844/1466844 [==============================] - 1052s 717us/step - loss: 0.2023 - val_loss: 0.1825\n",
      "CPU times: user 1h 10min 8s, sys: 1h 3min 40s, total: 2h 13min 49s\n",
      "Wall time: 33min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Fit RNN model to train data\n",
    "\n",
    "# Set hyper parameters for the model\n",
    "BATCH_SIZE = 512 * 3\n",
    "epochs = 2\n",
    "\n",
    "# Calculate learning rate decay\n",
    "exp_decay = lambda init, fin, steps: (init/fin)**(1/(steps-1)) - 1\n",
    "steps = int(len(X_train['name']) / BATCH_SIZE) * epochs\n",
    "lr_init, lr_fin = 0.005, 0.001\n",
    "lr_decay = exp_decay(lr_init, lr_fin, steps)\n",
    "\n",
    "# Create model and fit it with training dataset.\n",
    "rnn_model = new_rnn_model(lr=lr_init, decay=lr_decay)\n",
    "rnn_model.fit(\n",
    "        X_train, Y_train, epochs=epochs, batch_size=BATCH_SIZE,\n",
    "        validation_data=(X_dev, Y_dev), verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define RMSL Error Function for checking prediction\n",
    "def rmsle(Y, Y_pred):\n",
    "    assert Y.shape == Y_pred.shape\n",
    "    return np.sqrt(np.mean(np.square(Y_pred - Y )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on validation data...\n",
      " RMSLE error: 0.42716072339897987\n",
      "CPU times: user 3.9 s, sys: 3.9 s, total: 7.79 s\n",
      "Wall time: 2.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Evaluating the model on validation data...\")\n",
    "Y_dev_preds_rnn = rnn_model.predict(X_dev, batch_size=BATCH_SIZE)\n",
    "print(\" RMSLE error:\", rmsle(Y_dev, Y_dev_preds_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693359/693359 [==============================] - 87s 125us/step\n"
     ]
    }
   ],
   "source": [
    "#prediction for test data\n",
    "rnn_preds = rnn_model.predict(X_test, batch_size=BATCH_SIZE, verbose=1)\n",
    "rnn_preds = np.expm1(rnn_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ridge modelling\n",
    "# Concatenate train - dev - test data for furthur handling\n",
    "full_df = pd.concat([train_df, dev_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handling missing values...\n",
      "CPU times: user 12.8 s, sys: 40 ms, total: 12.9 s\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Handling missing values...\")\n",
    "full_df['category_name'] = full_df['category_name'].fillna('missing').astype(str)\n",
    "full_df['subcat_0'] = full_df['subcat_0'].astype(str)\n",
    "full_df['subcat_1'] = full_df['subcat_1'].astype(str)\n",
    "full_df['subcat_2'] = full_df['subcat_2'].astype(str)\n",
    "full_df['brand_name'] = full_df['brand_name'].fillna('missing').astype(str)\n",
    "full_df['shipping'] = full_df['shipping'].astype(str)\n",
    "full_df['item_condition_id'] = full_df['item_condition_id'].astype(str)\n",
    "full_df['desc_len'] = full_df['desc_len'].astype(str)\n",
    "full_df['name_len'] = full_df['name_len'].astype(str)\n",
    "full_df['item_description'] = full_df['item_description'].fillna('No description yet').astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing data for Ridge Modeling...\n",
      "(2175020, 323857) (1466844, 323857) (14817, 323857) (693359, 323857)\n",
      "CPU times: user 8min 40s, sys: 10.5 s, total: 8min 51s\n",
      "Wall time: 8min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Vectorizing data for Ridge Modeling...\")\n",
    "default_preprocessor = CountVectorizer().build_preprocessor()\n",
    "def build_preprocessor(field):\n",
    "    field_idx = list(full_df.columns).index(field)\n",
    "    return lambda x: default_preprocessor(x[field_idx])\n",
    "\n",
    "vectorizer = FeatureUnion([\n",
    "    ('name', CountVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=50000,\n",
    "        preprocessor=build_preprocessor('name'))),\n",
    "    ('subcat_0', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('subcat_0'))),\n",
    "    ('subcat_1', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('subcat_1'))),\n",
    "    ('subcat_2', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('subcat_2'))),\n",
    "    ('brand_name', CountVectorizer(\n",
    "        token_pattern='.+',\n",
    "        preprocessor=build_preprocessor('brand_name'))),\n",
    "    ('shipping', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('shipping'))),\n",
    "    ('item_condition_id', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('item_condition_id'))),\n",
    "    ('desc_len', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('desc_len'))),\n",
    "    ('name_len', CountVectorizer(\n",
    "        token_pattern='\\d+',\n",
    "        preprocessor=build_preprocessor('name_len'))),\n",
    "    ('item_description', TfidfVectorizer(\n",
    "        ngram_range=(1, 3),\n",
    "        max_features=100000,\n",
    "        preprocessor=build_preprocessor('item_description'))),\n",
    "])\n",
    "\n",
    "X = vectorizer.fit_transform(full_df.values)\n",
    "\n",
    "X_train = X[:n_trains]\n",
    "Y_train = train_df.target.values.reshape(-1, 1)\n",
    "\n",
    "X_dev = X[n_trains:n_trains+n_devs]\n",
    "Y_dev = dev_df.target.values.reshape(-1, 1)\n",
    "\n",
    "X_test = X[n_trains+n_devs:]\n",
    "print(X.shape, X_train.shape, X_dev.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Ridge model on training examples...\n",
      "CPU times: user 5min 30s, sys: 4.48 s, total: 5min 34s\n",
      "Wall time: 5min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Fitting Ridge model on training examples...\")\n",
    "ridge_model = Ridge(\n",
    "    solver='auto', fit_intercept=True, alpha=1.0,\n",
    "    max_iter=100, normalize=False, tol=0.05, random_state = 1,\n",
    ")\n",
    "ridge_modelCV = RidgeCV(\n",
    "    fit_intercept=True, alphas=[5.0],\n",
    "    normalize=False, cv = 2, scoring='neg_mean_squared_error',\n",
    ")\n",
    "ridge_model.fit(X_train, Y_train)\n",
    "ridge_modelCV.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSL error on dev set: 0.44139972293595137\n"
     ]
    }
   ],
   "source": [
    "#Evaluating Ridge model on dev data\n",
    "Y_dev_preds_ridge = ridge_model.predict(X_dev)\n",
    "Y_dev_preds_ridge = Y_dev_preds_ridge.reshape(-1, 1)\n",
    "print(\"RMSL error on dev set:\", rmsle(Y_dev, Y_dev_preds_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RMSL error on dev set: 0.43950296832705354\n"
     ]
    }
   ],
   "source": [
    "Y_dev_preds_ridgeCV = ridge_modelCV.predict(X_dev)\n",
    "Y_dev_preds_ridgeCV = Y_dev_preds_ridgeCV.reshape(-1, 1)\n",
    "print(\"CV RMSL error on dev set:\", rmsle(Y_dev, Y_dev_preds_ridgeCV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 520 ms, sys: 0 ns, total: 520 ms\n",
      "Wall time: 518 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#prediction for test data\n",
    "ridge_preds = ridge_model.predict(X_test)\n",
    "ridge_preds = np.expm1(ridge_preds)\n",
    "ridgeCV_preds = ridge_modelCV.predict(X_test)\n",
    "ridgeCV_preds = np.expm1(ridgeCV_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 11.7 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#combine all predictions\n",
    "def aggregate_predicts3(Y1, Y2, Y3, ratio1, ratio2):\n",
    "    assert Y1.shape == Y2.shape\n",
    "    return Y1 * ratio1 + Y2 * ratio2 + Y3 * (1.0 - ratio1-ratio2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 656 ms, sys: 0 ns, total: 656 ms\n",
      "Wall time: 652 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#ratio optimum finder for 3 models\n",
    "best1 = 0\n",
    "best2 = 0\n",
    "lowest = 0.99\n",
    "for i in range(100):\n",
    "    for j in range(100):\n",
    "        r = i*0.01\n",
    "        r2 = j*0.01\n",
    "        if r+r2 < 1.0:\n",
    "            Y_dev_preds = aggregate_predicts3(Y_dev_preds_rnn, Y_dev_preds_ridgeCV, Y_dev_preds_ridge, r, r2)\n",
    "            fpred = rmsle(Y_dev, Y_dev_preds)\n",
    "            if fpred < lowest:\n",
    "                best1 = r\n",
    "                best2 = r2\n",
    "                lowest = fpred\n",
    "Y_dev_preds = aggregate_predicts3(Y_dev_preds_rnn, Y_dev_preds_ridgeCV, Y_dev_preds_ridge, best1, best2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Best) RMSL error for RNN + Ridge + RidgeCV on dev set: 0.41835905730014744\n"
     ]
    }
   ],
   "source": [
    "print(\"(Best) RMSL error for RNN + Ridge + RidgeCV on dev set:\", rmsle(Y_dev, Y_dev_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed time:\n",
      "0:57:56.283362\n"
     ]
    }
   ],
   "source": [
    "# best predicted submission\n",
    "preds = aggregate_predicts3(rnn_preds, ridgeCV_preds, ridge_preds, best1, best2)\n",
    "submission = pd.DataFrame({\n",
    "        \"test_id\": test_df.test_id,\n",
    "        \"price\": preds.reshape(-1),\n",
    "})\n",
    "submission.to_csv(\"./rnn_ridge_submission.csv\", index=False)\n",
    "print(\"completed time:\")\n",
    "stop_real = datetime.now()\n",
    "execution_time_real = stop_real-start_real \n",
    "print(execution_time_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
